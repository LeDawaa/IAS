{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import string\n",
    "import win32gui\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from tkinter import *\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageOps, ImageGrab\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to download the EMNIST dataset from\n",
    "# https://www.kaggle.com/datasets/crawford/emnist\n",
    "# and extract it to the emnist folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Etape 1 : extraction du dataset #####\n",
    "\n",
    "# Function to save an image with the corresponding label in a specified directory\n",
    "def save_image(image, label, save_dir, index):\n",
    "    with Image.fromarray(image) as img:\n",
    "        # Rotate the image by -90 degrees and flip it horizontally\n",
    "        img = img.rotate(-90).transpose(Image.Transpose.FLIP_LEFT_RIGHT)\n",
    "        # Define the save path for the image, including the label and index\n",
    "        save_path = save_dir / str(label) / f\"image_{index}.png\"\n",
    "        # Create the directory for the label if it doesn't exist\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # Save the image to the defined path\n",
    "        img.save(save_path)\n",
    "\n",
    "# Function to save images and their labels from EMNIST dataset\n",
    "def save_images(folder):\n",
    "    # Load images from the EMNIST dataset\n",
    "    images = idx2numpy.convert_from_file(f\"emnist/emnist_source_files/emnist-byclass-{folder}-images-idx3-ubyte\")\n",
    "    # Load labels corresponding to the images\n",
    "    labels = idx2numpy.convert_from_file(f\"emnist/emnist_source_files/emnist-byclass-{folder}-labels-idx1-ubyte\")\n",
    "    # Define the save directory for the images\n",
    "    save_dir = Path(f\"images/{folder}\")\n",
    "    \n",
    "    # Use ThreadPoolExecutor to save images concurrently for improved performance\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Submit tasks to save each image with its corresponding label\n",
    "        [executor.submit(save_image, images[i], labels[i], save_dir, i) for i in range(images.shape[0])]\n",
    "\n",
    "# Save training images from the EMNIST dataset\n",
    "save_images('train')\n",
    "# Save testing images from the EMNIST dataset\n",
    "save_images('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Etape 2 : data augmentation #####\n",
    "\n",
    "categories = [str(x) for x in range(10, 36)]\n",
    "\n",
    "# Function to create a dataset with optional data augmentation\n",
    "def create_data(train_test, aug):\n",
    "    data_X, data_Y = [], []\n",
    "    base_path = f\"images/{train_test}\"\n",
    "    # Load images and labels for each category\n",
    "    for class_num, category in enumerate(categories):\n",
    "        img_paths = glob(os.path.join(base_path, category, '*.png'))\n",
    "        data_X.extend([cv2.resize(cv2.imread(img_path, cv2.IMREAD_GRAYSCALE), (28, 28)) for img_path in img_paths[:10000]])\n",
    "        data_Y.extend([class_num] * min(len(img_paths), 10000))\n",
    "    \n",
    "    # Convert data to numpy arrays and normalize pixel values\n",
    "    data_X = np.array(data_X).reshape(-1, 28, 28, 1) / 255.0\n",
    "    data_Y = np_utils.to_categorical(data_Y)\n",
    "    \n",
    "    # Augment the data if specified and it's the training set\n",
    "    if train_test == 'train' and aug:\n",
    "        # Define the data augmentation pipeline\n",
    "        datagen = ImageDataGenerator(rotation_range=10,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    zoom_range=0.1,\n",
    "                                    horizontal_flip=True)\n",
    "        \n",
    "        # Fit the data generator on the training data\n",
    "        datagen.fit(data_X)\n",
    "        \n",
    "        # Generate augmented images and labels for each category\n",
    "        for class_num, category in enumerate(categories):\n",
    "            num_samples = sum(data_Y[:, class_num] == 1)\n",
    "            while num_samples < 10000:\n",
    "                X_batch = data_X[data_Y[:, class_num] == 1]\n",
    "                Y_batch = data_Y[data_Y[:, class_num] == 1]\n",
    "                \n",
    "                # Generate augmented images and append them to the dataset\n",
    "                for X_aug_batch, Y_aug_batch in datagen.flow(X_batch, Y_batch, batch_size=len(X_batch)):\n",
    "                    aug_size = min(len(X_aug_batch), 10000 - num_samples)\n",
    "                    \n",
    "                    data_X = np.concatenate([data_X, np.array(X_aug_batch[:aug_size]).reshape(-1, 28, 28, 1)], axis=0)\n",
    "                    data_Y = np.concatenate([data_Y, np.array(Y_aug_batch[:aug_size])], axis=0)\n",
    "                    \n",
    "                    num_samples += len(X_aug_batch)\n",
    "                    if num_samples >= 10000:\n",
    "                        break\n",
    "    \n",
    "    # Shuffle the data\n",
    "    data = list(zip(data_X, data_Y))\n",
    "    random.shuffle(data)\n",
    "    data_X, data_Y = zip(*data)\n",
    "    \n",
    "    # Save the data to a numpy file\n",
    "    np.savez(f'dataset_{train_test}{\"_aug\" if aug else \"\"}', X=data_X, Y=data_Y)\n",
    "\n",
    "# Create datasets concurrently using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.submit(create_data, 'train', True)   # Augmented training set\n",
    "    executor.submit(create_data, 'train', False)  # Non-augmented training set\n",
    "    executor.submit(create_data, 'test', False)   # Non-augmented test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base path for the training images\n",
    "base_path = \"images/train\"\n",
    "# Initialize a list to store the number of images per category\n",
    "num_images = []\n",
    "\n",
    "# Iterate through each class (category) and count the number of images\n",
    "for class_num in range(10, 36):\n",
    "    category = str(class_num)\n",
    "    num_files = len(os.listdir(os.path.join(base_path, category)))\n",
    "    num_images.append(num_files)\n",
    "\n",
    "# Create a bar chart to visualize the number of images per class\n",
    "plt.bar(range(len(categories)), num_images)\n",
    "# Set the x-axis ticks and labels to represent the categories\n",
    "plt.xticks(range(len(categories)), categories)\n",
    "# Set the title of the chart\n",
    "plt.title('Number of images per class')\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the augmented training dataset from the numpy file\n",
    "data = np.load('dataset_train_aug.npz')\n",
    "# Extract the labels by finding the index of the maximum value along the one-hot encoded axis\n",
    "labels = np.argmax(data['Y'], axis=1)\n",
    "\n",
    "# Count the number of occurrences of each class in the dataset\n",
    "counts = [np.sum(labels == i) for i in range(len(categories))]\n",
    "\n",
    "# Create a bar chart to visualize the number of images per class\n",
    "plt.bar(categories, counts)\n",
    "# Set the title of the chart\n",
    "plt.title('Number of images per class')\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Etape 3 : le modèle #####\n",
    "\n",
    "# Load the training and testing datasets from the numpy files\n",
    "file = np.load('dataset_train.npz')\n",
    "train_images, train_labels = file['X'], file['Y']\n",
    "\n",
    "file = np.load('dataset_test.npz')\n",
    "test_images, test_labels = file['X'], file['Y']\n",
    "\n",
    "# Define the model checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint('best_model_2.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "# Define the CNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model and store the training history\n",
    "history = model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=30, batch_size=32, callbacks=[checkpoint_callback])\n",
    "\n",
    "# Plot the model accuracy over time (epochs) for training and testing datasets\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the model loss over time (epochs) for training and testing datasets\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model from the saved file\n",
    "model = load_model(\"best_model.h5\")\n",
    "\n",
    "# Load the testing dataset from the numpy file\n",
    "file = np.load('dataset_test.npz')\n",
    "test_images, test_labels = file['X'], file['Y']\n",
    "\n",
    "# Predict the probabilities for each class using the model\n",
    "y_probs = model.predict(test_images)\n",
    "\n",
    "# Determine the class with the highest probability as the predicted class\n",
    "y_pred = y_probs.argmax(axis=1)\n",
    "\n",
    "# Convert test labels from one-hot encoded format to integers\n",
    "test_labels_int = test_labels.argmax(axis=1)\n",
    "\n",
    "# Calculate the confusion matrix comparing the predicted classes to the true classes\n",
    "cm = tf.math.confusion_matrix(labels=test_labels_int, predictions=y_pred)\n",
    "\n",
    "# Plot the confusion matrix using Seaborn's heatmap\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "# Save the confusion matrix plot as an image\n",
    "plt.savefig('plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Etape 4 : séparation de mots en caractères et interface graphique pour tester notre écriture #####\n",
    "\n",
    "# Load the best model from the saved file\n",
    "model = load_model(\"best_model.h5\")\n",
    "\n",
    "# Function to predict the letter from the image\n",
    "def predict_digit(img):\n",
    "    # Resize image to 28x28 pixels\n",
    "    img = img.resize((28,28))\n",
    "    # Convert RGB to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    # Reshape to support our model input and normalize\n",
    "    img = img.reshape(1,28,28,1)\n",
    "    img = img/255.0\n",
    "    # Predict the class\n",
    "    res = model.predict([img])[0]\n",
    "    return string.ascii_uppercase[np.argmax(res)], max(res)\n",
    "\n",
    "# Define the main application class\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "        self.x = self.y = 0\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=900, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 32))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command = self.classify_handwriting)\n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "        # Bind canvas events\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "\n",
    "    # Function to clear the canvas\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.label.configure(text=\"Thinking..\")\n",
    "\n",
    "        # Function to group connected components by line\n",
    "    def group_components_by_line(self, stats, y_tolerance=20):\n",
    "        # Sort the stats array (excluding the background component at index 0) by the top-left y-coordinate (stat[1]) and then by the top-left x-coordinate (stat[0])\n",
    "        stats_sorted = sorted(stats[1:], key=lambda stat: (stat[1], stat[0]))\n",
    "        \n",
    "        # Initialize the list of grouped stats and the current line\n",
    "        grouped_stats = []\n",
    "        current_line = []\n",
    "\n",
    "        # Iterate through the sorted stats\n",
    "        for stat in stats_sorted:\n",
    "            # If the current line is empty, add the first stat to the line\n",
    "            if not current_line:\n",
    "                current_line.append(stat)\n",
    "            # If the vertical distance between the current stat and the previous stat is less than or equal to y_tolerance,\n",
    "            # it means they belong to the same line, so add the current stat to the current line\n",
    "            elif abs(stat[1] - current_line[-1][1]) <= y_tolerance:\n",
    "                current_line.append(stat)\n",
    "            # If the vertical distance is greater than y_tolerance, it means we have reached a new line\n",
    "            else:\n",
    "                # Sort the current line by the top-left x-coordinate (s[0]) and append it to the grouped_stats list\n",
    "                grouped_stats.append(sorted(current_line, key=lambda s: s[0]))\n",
    "                # Reset the current line to start a new line with the current stat\n",
    "                current_line = [stat]\n",
    "\n",
    "        # If there are any remaining stats in the current line, sort them by the top-left x-coordinate (s[0]) and append them to the grouped_stats list\n",
    "        if current_line:\n",
    "            grouped_stats.append(sorted(current_line, key=lambda s: s[0]))\n",
    "\n",
    "        return grouped_stats\n",
    "\n",
    "    # Function to classify the handwriting on the canvas\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # Get the handle of the canvas\n",
    "        rect = win32gui.GetWindowRect(HWND) # Get the coordinate of the canvas\n",
    "        im = ImageGrab.grab(rect)\n",
    "\n",
    "        # Preprocess the image\n",
    "        gray = cv2.cvtColor(np.array(im), cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        _, _, stats, _ = cv2.connectedComponentsWithStats(thresh)\n",
    "\n",
    "        # Group connected components by line\n",
    "        lines = self.group_components_by_line(stats)\n",
    "\n",
    "        # Iterate over each line and perform character recognition\n",
    "        margin_size = 50\n",
    "        border_color = (255, 255, 255)\n",
    "        predictions = []\n",
    "\n",
    "        for line in lines:\n",
    "            line_predictions = []\n",
    "            for i in range(len(line)):\n",
    "                x, y, w, h, _ = line[i]\n",
    "                # Add a border around the cropped image to avoid cutting off the edges of the character\n",
    "                image_with_border = ImageOps.expand(im.crop((x, y, x+w, y+h)), border=(margin_size, margin_size, margin_size, margin_size), fill=border_color)\n",
    "                # Invert the image and resize it to 28x28 pixels\n",
    "                image_with_border = ImageOps.invert(image_with_border).resize((28,28))\n",
    "                # Predict the character and its probability\n",
    "                digit, acc = predict_digit(image_with_border)\n",
    "                line_predictions.append((digit, acc))\n",
    "            predictions.append(line_predictions)\n",
    "\n",
    "        # Display the predictions in a formatted text\n",
    "        text, word = '', ''\n",
    "        for prediction in predictions:\n",
    "            for pred in prediction:\n",
    "                text += f\"Letter: {pred[0]}, Accuracy: {pred[1]:.3f} \\n\"\n",
    "                word += pred[0]\n",
    "            text += '\\n'\n",
    "            word += '\\n'\n",
    "        text += f\"Word:\\n{word}\"\n",
    "                \n",
    "        self.label.configure(text=text)\n",
    "\n",
    "    def draw_lines(self, event):\n",
    "        r = 8\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        self.canvas.create_oval(self.x - r, self.y - r, self.x + r, self.y + r, fill='black')\n",
    "\n",
    "app = App()\n",
    "mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
